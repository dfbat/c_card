{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea51ded7-ce08-4286-8967-7e1f65a2e866",
   "metadata": {},
   "source": [
    "# Hito 1\n",
    "## Parte Teórica:\n",
    "\n",
    "## ¿Qué es una red neuronal?\n",
    "Una red neuronal es un modelo computacional inspirado en la estructura y el funcionamiento del cerebro humano. Se compone de nodos (neuronas artificiales) organizados en capas y conectados mediante pesos sinápticos. Estas redes son utilizadas para tareas de aprendizaje automático como clasificación, regresión y reconocimiento de patrones.\n",
    "\n",
    "### Componentes principales de una red neuronal:\n",
    "1. **Neuronas**: Elementos fundamentales que procesan la información.\n",
    "2. **Capas**:\n",
    "   - **Capa de entrada**: Recibe los datos de entrada.\n",
    "   - **Capas ocultas**: Procesan la información aplicando funciones de activación.\n",
    "   - **Capa de salida**: Genera el resultado final.\n",
    "3. **Pesos y sesgos**: Parámetros ajustables que determinan la influencia de cada conexión.\n",
    "4. **Funciones de activación**: Transforman la entrada de cada neurona y permiten la modelización de relaciones no lineales.\n",
    "5. **Algoritmo de entrenamiento**: Método para ajustar los pesos y mejorar la precisión del modelo.\n",
    "\n",
    "## Proceso de Backpropagation\n",
    "El **backpropagation** es un algoritmo de optimización utilizado para entrenar redes neuronales. Su objetivo es ajustar los pesos de la red para minimizar el error en la predicción.\n",
    "\n",
    "### Pasos del backpropagation:\n",
    "1. **Propagación hacia adelante**: Se calcula la salida de la red neuronal mediante los valores actuales de los pesos.\n",
    "2. **Cálculo del error**: Se compara la salida obtenida con la salida esperada y se calcula el error utilizando una función de pérdida.\n",
    "3. **Propagación hacia atrás**:\n",
    "   - Se calcula el gradiente del error con respecto a los pesos de la red.\n",
    "   - Se actualizan los pesos mediante el algoritmo de optimización (ej. descenso de gradiente).\n",
    "4. **Repetición**: El proceso se repite hasta que el error sea mínimo y la red alcance un buen desempeño.\n",
    "\n",
    "### Importancia del Backpropagation:\n",
    "- Permite el ajuste eficiente de los pesos de la red.\n",
    "- Es fundamental para el entrenamiento de redes neuronales profundas.\n",
    "- Ayuda a mejorar la precisión del modelo en tareas complejas.\n",
    "\n",
    "## Funciones de Activación Comunes\n",
    "Las funciones de activación transforman la entrada de cada neurona y permiten modelar relaciones no lineales. A continuación, se describen tres funciones populares:\n",
    "\n",
    "1. **Sigmoide**\n",
    "   - Rango de salida: (0, 1)\n",
    "   - Suaviza los valores de entrada y es útil para problemas de clasificación binaria.\n",
    "   - Desventaja: Puede causar problemas de gradientes pequeños, ralentizando el entrenamiento.\n",
    "\n",
    "2. **ReLU (Rectified Linear Unit)**\n",
    "   - Define la salida como: f(x) = max(0, x).\n",
    "   - Ventajas: Simple, eficiente y mitiga el problema del gradiente que desaparece.\n",
    "   - Desventaja: No activa neuronas con entradas negativas (\"Neuronas muertas\").\n",
    "\n",
    "3. **Tangente Hiperbólica (Tanh)**\n",
    "   - Rango de salida: (-1, 1).\n",
    "   - Proporciona valores más amplios que la sigmoide, lo que mejora la propagación del gradiente.\n",
    "   - Útil en redes que requieren modelar relaciones más complejas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9254b1-a117-4cd0-a8ee-27a2bc4311e2",
   "metadata": {},
   "source": [
    "# Hito 1\n",
    "## Parte Práctica:\n",
    "- Utilice el dataset proporcionado para desarrollar un modelo de red neuronal que detecte transacciones fraudulentas: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "- Cargue el dataset en tu Jupyter Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b450d-71df-4109-ba91-3131c31d0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones básicas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Datasets y métricas\n",
    "from sklearn.datasets import make_classification, make_moons, make_circles\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# TensorFlow y Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#Cargar el conjunto de datos\n",
    "df = pd.read_csv('../Datos/creditcard.csv')\n",
    "# Mostrar las primeras filas para verificar la carga\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62e91a5-913c-4bfd-9a70-46bae6b14710",
   "metadata": {},
   "source": [
    "- Preprocese los datos, incluyendo la normalización de las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35568c-e006-45ce-b456-2312be6202ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Seleccionar las características numéricas para normalizar\n",
    "numeric_features = ['Time', 'Amount']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Escalador\n",
    "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b04d94-fe07-449f-8434-cc2167a2e8f7",
   "metadata": {},
   "source": [
    "- Construya una red neuronal simple utilizando Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f6538-2075-4398-92f3-c97733bc6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(df.shape[1]-1,))) # capa de entrada con 64 neuronas\n",
    "model.add(Dense(32, activation='relu')) # capa oculta con 32 neuronas\n",
    "model.add(Dense(1, activation='sigmoid')) # capa de salida\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluar el modelo (opcional)\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f150749-42dc-46a7-9a78-80134157e970",
   "metadata": {},
   "source": [
    "- Entrene el modelo y evalúe su precisión en un conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989d636-c01f-4b51-a7c3-7d4a79c16abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar los datos en conjuntos de entrenamiento y prueba\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% para entrenamiento, 20% para prueba\n",
    "\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "# Evaluar el modelo con los datos de prueba\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss en datos de prueba: {loss}, Accuracy en datos de prueba: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b086d-2360-4260-a067-0651957a0118",
   "metadata": {},
   "source": [
    "- Visualice las pérdidas y la precisión durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5750f-0ce9-4f01-9d0b-7b846119c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo y almacenar el historial\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Extraer los valores de pérdida y precisión\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Crear las gráficas de pérdida y precisión\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Gráfico de pérdida\n",
    "ax[0].plot(train_loss, label='Entrenamiento', color='blue')\n",
    "ax[0].plot(val_loss, label='Validación', color='orange')\n",
    "ax[0].set_title('Evolución de la Pérdida')\n",
    "ax[0].set_xlabel('Épocas')\n",
    "ax[0].set_ylabel('Pérdida')\n",
    "ax[0].legend()\n",
    "\n",
    "# Gráfico de precisión\n",
    "ax[1].plot(train_acc, label='Entrenamiento', color='blue')\n",
    "ax[1].plot(val_acc, label='Validación', color='orange')\n",
    "ax[1].set_title('Evolución de la Precisión')\n",
    "ax[1].set_xlabel('Épocas')\n",
    "ax[1].set_ylabel('Precisión')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
